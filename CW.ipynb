{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR/W+7WR+jK7BinF45trn+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkvkrll/-Introduction-to-Natural-Language-Processing/blob/main/CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfAHVejDREj4"
      },
      "outputs": [],
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "rX5QBwpyRQ0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words"
      ],
      "metadata": {
        "id": "u939spOERTHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install annoy"
      ],
      "metadata": {
        "id": "axJXOT9SRVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import annoy\n",
        "import pickle\n",
        "import string\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from gensim.models import Word2Vec, FastText\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from telegram.ext  import Updater, CommandHandler, MessageHandler, filters\n",
        "from telegram import Animation"
      ],
      "metadata": {
        "id": "FS52O7DvRaA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8dpHFN5wRc2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_dataset = pd.read_csv(\"/content/drive/My Drive/ProductsDataset.csv\")\n",
        "input_file = \"/content/drive/My Drive/Otvety.txt\"\n",
        "output_file = \"/content/drive/My Drive/prepared_answers.txt\""
      ],
      "metadata": {
        "id": "2K7aVaC0Rh8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_txt(line):\n",
        "    \"\"\"Строковый препроцессинг текстовой строки\"\"\"\n",
        "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
        "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
        "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
        "    return spls"
      ],
      "metadata": {
        "id": "TNKTbOcCRuuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_txt(txt, idfs, midf):\n",
        "    n_ft = 0\n",
        "    vector_ft = np.zeros(100)\n",
        "    for word in txt:\n",
        "        if word in modelFT:\n",
        "            vector_ft += modelFT[word] * idfs.get(word, midf)\n",
        "            n_ft += idfs.get(word, midf)\n",
        "    return vector_ft / n_ft"
      ],
      "metadata": {
        "id": "NOPZ2BuyRx9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert True\n",
        "\n",
        "#Small preprocess of the answers\n",
        "\n",
        "question = None\n",
        "written = False\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf8\") as fout:\n",
        "    with open(input_file, \"r\", encoding=\"utf8\") as fin:\n",
        "        for line in tqdm_notebook(fin):\n",
        "            if line.startswith(\"---\"):\n",
        "                written = False\n",
        "                continue\n",
        "            if not written and question is not None:\n",
        "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
        "                written = True\n",
        "                question = None\n",
        "                continue\n",
        "            if not written:\n",
        "                question = line.strip()\n",
        "                continue"
      ],
      "metadata": {
        "id": "rlSsPjxRR0X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "assert True\n",
        "\n",
        "# Preprocess for models fitting\n",
        "\n",
        "sentences = []\n",
        "\n",
        "morpher = MorphAnalyzer()\n",
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(string.punctuation)\n",
        "c = 0\n",
        "\n",
        "with open(input_file, \"r\", encoding=\"utf8\") as fin:\n",
        "    for line in tqdm_notebook(fin):\n",
        "        spls = preprocess_txt(line)\n",
        "        sentences.append(spls)\n",
        "        c += 1\n",
        "        if c > 500000:\n",
        "            break"
      ],
      "metadata": {
        "id": "u53rJBKIR2se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [i for i in sentences if len(i) > 2]\n",
        "modelFT = FastText(sentences=sentences, size=100, min_count=1, window=5)\n",
        "modelFT.save(\"ft_model\")"
      ],
      "metadata": {
        "id": "gLOmNW6KR4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "modelFT = FastText.load(\"ft_model\")\n",
        "ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
        "\n",
        "index_map = {}\n",
        "counter = 0\n",
        "\n",
        "with open(output_file, \"r\", encoding=\"utf8\") as f:\n",
        "    for line in tqdm_notebook(f):\n",
        "        n_ft = 0\n",
        "        spls = line.split(\"\\t\")\n",
        "        index_map[counter] = spls[1]\n",
        "        question = preprocess_txt(spls[0])\n",
        "        vector_ft = np.zeros(100)\n",
        "        for word in question:\n",
        "            if word in modelFT:\n",
        "                vector_ft += modelFT[word]\n",
        "                n_ft += 1\n",
        "        if n_ft > 0:\n",
        "            vector_ft = vector_ft / n_ft\n",
        "        ft_index.add_item(counter, vector_ft)\n",
        "            \n",
        "        counter += 1\n",
        "\n",
        "ft_index.build(10)\n",
        "ft_index.save('speaker.ann')"
      ],
      "metadata": {
        "id": "dTe3Ywa7R6ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
        "ft_index.load('speaker.ann')"
      ],
      "metadata": {
        "id": "iS0RfKb9R8_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_index.get_nns_by_vector(np.zeros(100), 2)"
      ],
      "metadata": {
        "id": "dFNRMxO0R_FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_dataset['text'] = products_dataset['title'] + \" \" + products_dataset[\"descrirption\"]\n",
        "products_dataset['text'] = products_dataset['text'].apply(lambda x: preprocess_txt(str(x)))\n",
        "products_dataset.head()"
      ],
      "metadata": {
        "id": "mkeulk8lSA03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 2))"
      ],
      "metadata": {
        "id": "BZ2sk8goSCx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = set(np.random.randint(0, len(index_map), len(products_dataset)))\n",
        "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in idxs]\n",
        "positive_texts = [\" \".join(val) for val in products_dataset['text'].values]"
      ],
      "metadata": {
        "id": "E9XRE5w9SFSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = negative_texts + positive_texts\n",
        "labels = np.zeros(len(dataset))\n",
        "labels[len(negative_texts):] = np.ones(len(positive_texts))"
      ],
      "metadata": {
        "id": "WXbiFqgOSHEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, \n",
        "                                                    stratify=labels, random_state=13)"
      ],
      "metadata": {
        "id": "ev-4QDIySIrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_vec = vectorizer.fit_transform(X_train)\n",
        "x_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression().fit(x_train_vec, y_train)"
      ],
      "metadata": {
        "id": "vcVOPJFqSKUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
      ],
      "metadata": {
        "id": "Bx6Q5uxESLyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert True\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/index_speaker.pkl\", \"wb\") as f:\n",
        "    pickle.dump(index_map, f)"
      ],
      "metadata": {
        "id": "xd7pjA41SNo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TfidfVectorizer().fit(X_train)"
      ],
      "metadata": {
        "id": "Tg2bFuhZSROt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(tfidf_vect.idf_)"
      ],
      "metadata": {
        "id": "Zpp9NPDVSTHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}\n",
        "idfs"
      ],
      "metadata": {
        "id": "LiOKpiK4SUj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
        "\n",
        "midf = np.mean(tfidf_vect.idf_)\n",
        "\n",
        "index_map_shop = {}\n",
        "counter = 0\n",
        "\n",
        "for i in tqdm_notebook(range(len(products_dataset))):\n",
        "    n_ft = 0\n",
        "    index_map_shop[counter] = (products_dataset.loc[i, \"title\"], products_dataset.loc[i, \"image_links\"])\n",
        "    vector_ft = np.zeros(100)\n",
        "    for word in products_dataset.loc[i, \"text\"]:\n",
        "        if word in modelFT:\n",
        "            vector_ft += modelFT[word] * idfs.get(word, midf)\n",
        "            n_ft += idfs.get(word, midf)\n",
        "    if n_ft > 0:\n",
        "        vector_ft = vector_ft / n_ft\n",
        "    ft_index_shop.add_item(counter, vector_ft)\n",
        "    counter += 1\n",
        "\n",
        "ft_index_shop.build(10)\n",
        "ft_index_shop.save('shop.ann')"
      ],
      "metadata": {
        "id": "7-20eIuXSWEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert True\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/index_shop.pkl\", \"wb\") as f:\n",
        "    pickle.dump(index_map, f)"
      ],
      "metadata": {
        "id": "AvGx3uAHSZIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_index_shop.get_nns_by_vector(np.zeros(100), 1, include_distances=True)"
      ],
      "metadata": {
        "id": "Psbboe-VSbEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install telegram"
      ],
      "metadata": {
        "id": "vvKY-FK3Scjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tornado\n",
        "!pip install tornado==4.5.3"
      ],
      "metadata": {
        "id": "xrEttSRbSeAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip uninstall telegram==0.0.1 "
      ],
      "metadata": {
        "id": "g5O6fmZYSfb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_msg = 'Привет. Я бот.  Чем могу помочь?'"
      ],
      "metadata": {
        "id": "DOpJCmpDShTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updater = Updater(token='')\n",
        "dispatcher = updater.dispatcher"
      ],
      "metadata": {
        "id": "A8B6no6USmRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def startCommand(bot, update):\n",
        "    bot.send_message(chat_id=update.message.chat_id, text=start_msg)"
      ],
      "metadata": {
        "id": "vTbQB8iCSoK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def textMessage(bot, update):\n",
        "    \n",
        "    input_txt = preprocess_txt(update.message.text)\n",
        "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
        "    prediction = lr.predict(vect)\n",
        "    \n",
        "    if prediction[0] == 1:\n",
        "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
        "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
        "        for item in ft_index_shop_val:\n",
        "            title, image = index_map_shop[item]\n",
        "            bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
        "        return\n",
        "    vect_ft = embed_txt(input_txt, {}, 1)\n",
        "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
        "    if distances[0] > 0.2:\n",
        "        print(distances[0])\n",
        "        bot.send_message(chat_id=update.message.chat_id, text=\"Чаво ?\")\n",
        "        return\n",
        "    bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])"
      ],
      "metadata": {
        "id": "a-CQHcguSp1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_command_handler = CommandHandler('start', startCommand)\n",
        "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
        "dispatcher.add_handler(start_command_handler)\n",
        "dispatcher.add_handler(text_message_handler)\n",
        "updater.start_polling(clean=True)\n",
        "updater.idle()"
      ],
      "metadata": {
        "id": "siAYHEH1Srr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}